{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOictBQ6MjeXlCXxvNDGx0T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd0KTZHOnQAZ","executionInfo":{"status":"ok","timestamp":1755637323237,"user_tz":-345,"elapsed":12780,"user":{"displayName":"irfan","userId":"17410180819991469094"}},"outputId":"df67b37a-e080-4150-dc77-1e7ba5e54365"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/315.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -qU \\\n","    langchain-pinecone==0.1.3 \\\n","    langchain-text-splitters==0.2.0 \\\n","    langchain==0.2.1 \\\n","    pinecone-notebooks==0.1.1 \\\n","    gradio \\\n","    groq \\\n","    langchain-groq \\\n","    PyPDF2 \\\n","    phonenumbers dateparser\n"]},{"cell_type":"code","source":["import os\n","import time\n","import asyncio\n","from langchain_text_splitters import MarkdownHeaderTextSplitter\n","from langchain_pinecone import PineconeEmbeddings, PineconeVectorStore\n","from langchain.chains import RetrievalQA\n","from pinecone import Pinecone, ServerlessSpec\n","from google.colab import userdata\n","import gradio as gr\n","from groq import Groq\n","from langchain_groq import ChatGroq\n","\n","os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')\n","os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n","\n","if not os.environ.get(\"PINECONE_API_KEY\"):\n","    print(\"Please set PINECONE_API_KEY environment variable\")\n","if not os.environ.get(\"GROQ_API_KEY\"):\n","    print(\"Please set GROQ_API_KEY environment variable\")\n","\n","def test_groq_connection():\n","    try:\n","        llm = ChatGroq(\n","            groq_api_key=os.environ.get('GROQ_API_KEY'),\n","            model_name=\"llama3-70b-8192\",\n","            temperature=0.0,\n","            max_retries=2,\n","            timeout=10\n","        )\n","        test_response = llm.invoke(\"Hello\")\n","        print(\"Groq connection test successful!\")\n","        return True\n","    except Exception as e:\n","        print(f\"Groq connection test failed: {e}\")\n","        return False\n","test_groq_connection()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnmPm_gpnhL7","executionInfo":{"status":"ok","timestamp":1755638599332,"user_tz":-345,"elapsed":2420,"user":{"displayName":"irfan","userId":"17410180819991469094"}},"outputId":"a70e6a6c-4622-4124-a3ca-d4e6751986d5"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Groq connection test successful!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["async def initialize_system(markdown_text):\n","    \"\"\"Initialize the RAG system with the provided markdown text\"\"\"\n","    try:\n","        headers_to_split_on = [\n","            (\"#\", \"Header 1\"),\n","            (\"##\", \"Header 2\")\n","        ]\n","        markdown_splitter = MarkdownHeaderTextSplitter(\n","            headers_to_split_on=headers_to_split_on, strip_headers=False\n","        )\n","        md_header_splits = markdown_splitter.split_text(markdown_text)\n","\n","        model_name = 'multilingual-e5-large'\n","        embeddings = PineconeEmbeddings(\n","            model=model_name,\n","            pinecone_api_key=os.environ.get('PINECONE_API_KEY')\n","        )\n","\n","        pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n","        cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n","        region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n","        spec = ServerlessSpec(cloud=cloud, region=region)\n","\n","        index_name = \"rag-chatbot\"\n","\n","        if index_name not in pc.list_indexes().names():\n","            pc.create_index(\n","                name=index_name,\n","                dimension=embeddings.dimension,\n","                metric=\"cosine\",\n","                spec=spec\n","            )\n","            while not pc.describe_index(index_name).status['ready']:\n","                time.sleep(1)\n","\n","        namespace = \"markdown-content\"\n","        docsearch = PineconeVectorStore.from_documents(\n","            documents=md_header_splits,\n","            index_name=index_name,\n","            embedding=embeddings,\n","            namespace=namespace\n","        )\n","\n","        llm = ChatGroq(\n","            groq_api_key=os.environ.get('GROQ_API_KEY'),\n","            model_name=\"llama-3.3-70b-versatile\",\n","            temperature=0.0\n","        )\n","\n","        qa = RetrievalQA.from_chain_type(\n","            llm=llm,\n","            chain_type=\"stuff\",\n","            retriever=docsearch.as_retriever(),\n","            return_source_documents=True\n","        )\n","\n","        return qa, llm\n","    except Exception as e:\n","        print(f\"Error in initialize_system: {str(e)}\")\n","        raise"],"metadata":{"id":"Vc9esVGgn0dZ","executionInfo":{"status":"ok","timestamp":1755638599395,"user_tz":-345,"elapsed":13,"user":{"displayName":"irfan","userId":"17410180819991469094"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["class ChatbotState:\n","    def __init__(self):\n","        self.qa = None\n","        self.llm = None\n","\n","state = ChatbotState()\n","\n","def extract_text_from_file(file):\n","    try:\n","        if file.name.endswith('.pdf'):\n","            import PyPDF2\n","            with open(file.name, 'rb') as f:\n","                reader = PyPDF2.PdfReader(f)\n","                text = \"\\n\".join([page.extract_text() for page in reader.pages])\n","                return text\n","        elif file.name.endswith(('.txt', '.md')):\n","            with open(file.name, 'r', encoding='utf-8') as f:\n","                return f.read()\n","        else:\n","            return f\"Unsupported file type: {file.name}\"\n","    except Exception as e:\n","        return f\"Error reading file: {str(e)}\"\n","\n","def submit_content(text_input, file_input):\n","    content = \"\"\n","\n","    if text_input.strip():\n","        content = text_input\n","    elif file_input is not None:\n","        content = extract_text_from_file(file_input)\n","    else:\n","        return \"Please enter text or upload a file.\", gr.update(visible=False)\n","\n","    if not content.strip():\n","        return \"The content is empty.\", gr.update(visible=False)\n","\n","    try:\n","        loop = asyncio.new_event_loop()\n","        asyncio.set_event_loop(loop)\n","        state.qa, state.llm = loop.run_until_complete(initialize_system(content))\n","        loop.close()\n","\n","        return (\"Content successfully loaded! You can now ask questions.\", gr.update(visible=True))\n","    except Exception as e:\n","        print(f\"Error in submit_content: {str(e)}\")\n","        return f\"Error: {str(e)}\", gr.update(visible=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyD5f4N5oXfE","executionInfo":{"status":"ok","timestamp":1755638599444,"user_tz":-345,"elapsed":39,"user":{"displayName":"irfan","userId":"17410180819991469094"}},"outputId":"8c6e0b42-661f-49e0-e780-b12339c5226a"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:asyncio:Unclosed client session\n","client_session: <aiohttp.client.ClientSession object at 0x794ab28ae8d0>\n"]}]},{"cell_type":"code","source":["import phonenumbers\n","import dateparser\n","from datetime import datetime, timedelta\n","import re\n","\n","class UserInfo:\n","    def __init__(self):\n","        self.name = None\n","        self.phone = None\n","        self.email = None\n","        self.appointment_date = None\n","        self.conversation_state = \"normal\"\n","\n","user_info = UserInfo()"],"metadata":{"id":"3kg97sOKIYpC","executionInfo":{"status":"ok","timestamp":1755638599496,"user_tz":-345,"elapsed":42,"user":{"displayName":"irfan","userId":"17410180819991469094"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def validate_email(email):\n","    \"\"\"Validate email format\"\"\"\n","    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n","    return re.match(pattern, email) is not None\n","\n","def validate_phone(phone):\n","    \"\"\"Validate phone number format\"\"\"\n","    try:\n","        pattern = r'^(\\+977-)?(98[0-9]{8}|97[0-9]{8}|96[0-9]{8})$'\n","        phone = re.sub(r'[\\s\\-\\(\\)]', '', phone.strip())\n","        if re.match(pattern, phone):\n","            return True\n","        parsed_phone = phonenumbers.parse(phone, None)\n","        return phonenumbers.is_valid_number(parsed_phone)\n","    except:\n","        return False"],"metadata":{"id":"_lM-wDDcIg9-","executionInfo":{"status":"ok","timestamp":1755638599500,"user_tz":-345,"elapsed":37,"user":{"displayName":"irfan","userId":"17410180819991469094"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def extract_date(text):\n","    \"\"\"Extract date from natural language\"\"\"\n","    try:\n","        parsed_date = dateparser.parse(text, languages=['en'])\n","        if parsed_date:\n","            return parsed_date.strftime(\"%Y-%m-%d\")\n","        return None\n","    except:\n","        return None\n","\n","def handle_appointment_request(message):\n","    global user_info\n","\n","    if user_info.conversation_state == \"normal\":\n","        user_info.conversation_state = \"collect_name\"\n","        return \"I'd be happy to help you book an appointment! First, what's your full name?\"\n","\n","    elif user_info.conversation_state == \"collect_name\":\n","        user_info.name = message.strip()\n","        user_info.conversation_state = \"collect_phone\"\n","        return f\"Nice to meet you, {user_info.name}! What's your phone number?\"\n","\n","    elif user_info.conversation_state == \"collect_phone\":\n","        if validate_phone(message):\n","            user_info.phone = message.strip()\n","            user_info.conversation_state = \"collect_email\"\n","            return \"Great! What's your email address?\"\n","        else:\n","            return \"Please enter a valid phone number (e.g., +977-9808535455 or 9808535455):\"\n","\n","    elif user_info.conversation_state == \"collect_email\":\n","        if validate_email(message):\n","            user_info.email = message.strip()\n","            user_info.conversation_state = \"collect_date\"\n","            return \"Perfect! When would you like to schedule the appointment? (e.g., 'next Monday', 'December 15th', 'tomorrow')\"\n","        else:\n","            return \"Please enter a valid email address (e.g., irfanAlam@email.com):\"\n","\n","    elif user_info.conversation_state == \"collect_date\":\n","        date = extract_date(message)\n","        if date:\n","            user_info.appointment_date = date\n","            confirmation = f\"\"\"\n","Thank You!Appointment Booked Successfully!\n","\n","Here are your details:\n","• Name: {user_info.name}\n","• Phone: {user_info.phone}\n","• Email: {user_info.email}\n","• Appointment Date: {user_info.appointment_date}\n","\n","We'll contact you at {user_info.phone} to confirm. Thank you!\n","            \"\"\"\n","            user_info.conversation_state = \"normal\"\n","            return confirmation\n","        else:\n","            return \"I couldn't understand that date. Please try again (e.g., 'next Monday', 'December 15th'):\""],"metadata":{"id":"kruTWBggIjvM","executionInfo":{"status":"ok","timestamp":1755638599513,"user_tz":-345,"elapsed":41,"user":{"displayName":"irfan","userId":"17410180819991469094"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["def process_query(message, history):\n","    global user_info\n","    appointment_keywords = ['call me', 'book appointment', 'schedule', 'meeting', 'call back', 'contact me']\n","    if any(keyword in message.lower() for keyword in appointment_keywords):\n","        return handle_appointment_request(message)\n","\n","    if user_info.conversation_state != \"normal\":\n","        return handle_appointment_request(message)\n","\n","    if state.qa is None:\n","        return \"Please submit content first before asking questions.\"\n","\n","    try:\n","        response = state.qa.invoke({\"query\": message})\n","        return response['result']\n","    except Exception as e:\n","        print(f\"Error in process_query: {str(e)}\")\n","        return f\"Error processing query: {str(e)}\"\n"],"metadata":{"id":"jLefDlXmoYxw","executionInfo":{"status":"ok","timestamp":1755638599518,"user_tz":-345,"elapsed":38,"user":{"displayName":"irfan","userId":"17410180819991469094"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["with gr.Blocks() as interface:\n","    gr.Markdown(\"ChatBot with appointment Booking\")\n","\n","    with gr.Row():\n","        with gr.Column():\n","            text_input = gr.TextArea(\n","                label=\"Or paste content here\",\n","                placeholder=\"Paste your document content here...\",\n","                lines=5\n","            )\n","\n","            file_input = gr.File(\n","                label=\"Upload document (PDF, TXT)\",\n","                file_types=[\".pdf\", \".txt\", \".md\"]\n","            )\n","\n","            submit_btn = gr.Button(\"Submit Content\")\n","\n","    status_msg = gr.Textbox(label=\"Status\", interactive=False)\n","\n","    with gr.Column(visible=False) as chat_interface:\n","        chatbot = gr.ChatInterface(\n","            fn=process_query,\n","            title=\"Document Q&A with Appointment Booking\",\n","            examples=[\n","                \"What is this document about?\",\n","                \"Book an appointment with me\",\n","                \"Call me to discuss this\",\n","                \"Schedule a meeting for next Monday\"\n","            ]\n","        )\n","\n","    submit_btn.click(\n","        fn=submit_content,\n","        inputs=[text_input, file_input],\n","        outputs=[status_msg, chat_interface]\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyyiG0fMofij","executionInfo":{"status":"ok","timestamp":1755638599922,"user_tz":-345,"elapsed":434,"user":{"displayName":"irfan","userId":"17410180819991469094"}},"outputId":"314b4245-2c12-4dea-c2e6-aed814aa085f"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n","  self.chatbot = Chatbot(\n"]}]},{"cell_type":"code","source":["# Run the interface\n","if __name__ == \"__main__\":\n","    interface.launch(share=True, debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":668},"id":"q7AUgIH2oh5d","executionInfo":{"status":"ok","timestamp":1755638723301,"user_tz":-345,"elapsed":123388,"user":{"displayName":"irfan","userId":"17410180819991469094"}},"outputId":"34a1f960-5262-49a4-824d-e8930eab4575"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://9bec0f1b9d88b4645d.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://9bec0f1b9d88b4645d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Error in process_query: Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.3-70b-versatile` in organization `org_01k31zg48cfrct5jjmppk8gvmr` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Requested 16764, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://9bec0f1b9d88b4645d.gradio.live\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tcXWuJN3Q8hK"},"execution_count":null,"outputs":[]}]}